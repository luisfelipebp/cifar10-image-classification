# Classificador de Imagens com CNN para o Dataset CIFAR-10

Este projeto implementa uma **Rede Neural Convolucional (CNN)** para classificar imagens do dataset **CIFAR-10**. O objetivo √© construir e treinar um modelo capaz de reconhecer 10 categorias diferentes de objetos em imagens coloridas de baixa resolu√ß√£o.

---

## Dataset: CIFAR-10 üñºÔ∏è

O [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) √© um dataset cl√°ssico utilizado para algoritmos de classifica√ß√£o de imagens. Ele √© composto por:

* **60.000 imagens** coloridas de 32x32 pixels.
* **10 classes** de objetos, com 6.000 imagens por classe.

As 10 classes s√£o: avi√£o, autom√≥vel, p√°ssaro, gato, cervo, cachorro, sapo, cavalo, navio e caminh√£o.

---

## Tecnologias Utilizadas üõ†Ô∏è

* **Python 3.x**
* **TensorFlow** e **Keras** para a constru√ß√£o e treinamento do modelo.
* **NumPy** para manipula√ß√£o de arrays.

---

## Metodologia

O projeto segue as seguintes etapas para a constru√ß√£o e avalia√ß√£o do classificador:

### 1. Pr√©-processamento dos Dados

Antes de alimentar a rede neural, os dados passaram pelas seguintes transforma√ß√µes:

* **Reshape:** As dimens√µes das imagens foram ajustadas para o formato que o TensorFlow espera: `(amostras, altura, largura, canais)`.
* **Normaliza√ß√£o:** Os valores dos pixels, originalmente entre 0 e 255, foram normalizados para o intervalo entre **0 e 1**. Isso √© feito dividindo todos os valores por 255, o que ajuda a acelerar a converg√™ncia durante o treinamento.
* **One-Hot Encoding:** Os r√≥tulos (labels) das classes, que eram n√∫meros inteiros de 0 a 9, foram convertidos para o formato categ√≥rico (vetores bin√°rios), que √© o formato esperado pela fun√ß√£o de perda `categorical_crossentropy`.

### 2. Arquitetura do Modelo

A Rede Neural Convolucional foi constru√≠da com a seguinte arquitetura:

| Camada | Tipo                 | Detalhes                                                 |
| :----- | :------------------- | :------------------------------------------------------- |
| 1      | `Conv2D`             | 32 filtros, kernel (3,3), ativa√ß√£o **ReLU** |
| 2      | `BatchNormalization` | Normaliza a sa√≠da da camada anterior                     |
| 3      | `MaxPooling2D`       | Janela de (2,2) para reduzir a dimensionalidade          |
| 4      | `Conv2D`             | 32 filtros, kernel (3,3), ativa√ß√£o **ReLU** |
| 5      | `BatchNormalization` | Normaliza a sa√≠da da camada anterior                     |
| 6      | `MaxPooling2D`       | Janela de (2,2)                                          |
| 7      | `Flatten`            | Transforma a matriz 2D em um vetor 1D                    |
| 8      | `Dense`              | Camada Densa com 128 neur√¥nios, ativa√ß√£o **ReLU** |
| 9      | `Dropout`            | Regulariza√ß√£o com taxa de **30%** para evitar overfitting |
| 10     | `Dense`              | Camada Densa com 128 neur√¥nios, ativa√ß√£o **ReLU** |
| 11     | `Dropout`            | Regulariza√ß√£o com taxa de **30%** |
| 12     | `Dense` (Sa√≠da)      | **10 neur√¥nios** (1 para cada classe), ativa√ß√£o **Softmax** |

* **Otimizador:** `adam`
* **Fun√ß√£o de Perda:** `categorical_crossentropy`

---


## Resultados üìä

O modelo foi treinado por 5 √©pocas, alcan√ßando os seguintes resultados no conjunto de valida√ß√£o:

* **Acur√°cia de Valida√ß√£o Final:** **~69.88%**
* **Perda de Valida√ß√£o Final:** **~0.8929**
